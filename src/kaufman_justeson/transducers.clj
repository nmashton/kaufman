;; Transducers for effecting the transformation from raw text to a
;; sequence of tagged lexemes.
(ns kaufman-justeson.transducers
  (:use [kaufman-justeson.functions]))

;; # Step 1. Parse the top level of hierarchical structure.

;; The remainder of the transformations applied to the data consist of
;; partitioning the sequence of lines on certain "meaningful" line patterns,
;; using the split to generate a new piece of metadata, and flattening
;; the resulting list while pushing the metadata from the split batch of
;; lines down to its components.

;; That is:
;;
;; 1. Start with a sequence of lines.
;; 2. Partition the sequence by matching on a predicate that checks for
;;    a "header" element at some level of structure.
;; 3. Create pairs from the partitioned sequence, matching headers with
;;    the content lines.
;; 4. Turn the first element of the pair into a piece of metadata and
;;    associate it with the content lines.
;; 5. If the sequence from step 1 had metadata, push it down to the
;;    content lines.

;; The first step applies to lines that start with %%, which are
;; delimiters of top-level semantic categories. We break on these
;; lines and use their contents as keys in the resulting map.

(def strip-percents
  "Strip lines that consist of nothing but %s.
  Such lines, unlike lines that just start with %%,
  are not meaningful and can be completely ignored."
  (filter
    #(not (re-seq #"^\%+\s*$" %))))

(def group-with-semantic-field-block
  "Partition the data by lines that start with %%.

  Also apply a cleaning function `clean-p-key`
  to strip off the meaningless crud that encloses the %%-keys."
  (comp
    (partition-by #(empty? (re-seq #"^\s*%% " %)))
    (partition-all 2)
    (map
      (fn [[[field] lines]]
        (with-meta
          lines
          {:semantic-field-block (clean-p-key field)})))))


;; # Step 2. Parse next level of structure: xx-delimiters.

;; Beneath the level of %%-delimiters, there is more structure to parse.
;; The next structural delimiter to split on is the line consisting of
;; xxs. Such a line marks a finer-grained semantic category.

;; Unlike lines starting with %%, xx-lines do not themselves contain
;; the semantic information we want to capture and use as a key. This
;; information is on the next line—when it exists, and unfortunately
;; it does not always exist!

;; In any case, because the xx-delimiters themselves are not meaningful,
;; we can partition on them and then filter them out.

(def split-on-xx-delimiters
  (mapcat
    (fn [block]
      (eduction (handle-xx block)))))

;; # Step 3. Parse next level of structure: ==-delimiters.

;; We now need to partition the blocks by the lines that consist
;; of equals-signs. These blocks denote sets of forms that share a root. But this
;; root is not in fact given in the text. So we just create an arbitrary
;; index by means of generated by `gensym`.

(def split-on-eq-delimiters
  (mapcat
    (fn [block]
      (eduction (handle-eq block)))))

;; # Step 4. Parse next level of structure: root headers.

;; At the next level, blocks of content are delimited by lines indicating
;; the reconstructed roots that items in the block share—or by other, similar-looking identifiers.
;; These delimiting lines are *almost* identifiable by their not having any leading
;; whitespace. Unfortunately, that's about the only thing which all of the
;; identifiers share—and many other things in the data also look like that!
;; I've done my best to weed out lines from the data that would throw
;; off detection of root headers ... but inevitably a certain amount of
;; error enters at this point. (TODO: fix all the problems.)

;; Breaking down blocks by putative root headers proceeds more
;; or less like previous stages of parsing.
;; First, however, it is necessary to weed out blank lines and remnants
;; of xx-headers from the tops of blocks of content, as these will
;; foil our attempts to detect root headers if left unattended.

(def eliminate-garbage
  "Weed out initial blanks and remnants of xx-headers."
  (map
    (fn [lines]
      (let [[fst & rst] lines]
        (if (or
              (.startsWith fst "     ")
              (empty? (.trim fst)))
            (if rst
              (with-meta rst (meta lines))
              rst)
            (with-meta lines (meta lines)))))))

(def eliminate-more-garbage
  "Weed out totally empty parts of the structure.
  This prevents problems shortly down the road."
  (map
    (fn [lines]
      (with-meta
        (filter #(not (empty? (.trim %))) lines)
        (meta lines)))))

(def eliminate-even-more-garbage
  "Perform yet another round of cleanups, using the trash-detection
  function `eliminable`."
  (map
    (fn [lines]
      (with-meta
        (filter (complement eliminable?) lines)
        (meta lines)))))

(def group-by-root-lines
  "Group lines by root headers."
  (comp
    ; input: [[:a, :b, :c], [:d, :e, :f]]
    ; output: [[[:a], [:b, :c]], [[:d], [:e, :f]]]
    (map
      (fn [lines]
        (with-meta
          (partition-by root? lines)
          (meta lines))))
    ; fixing the defective groups
    (map
      (fn [groups]
        (with-meta
          (case (count groups)
            1 (cons '() groups)
            3 (rest groups)
            groups)
          (meta groups))))
    ; creating pairs
    (mapcat
      (fn [groups]
        (map
          #(with-meta % (meta groups))
          (partition-all 2 groups))))
    (map
      (fn [[root lines :as block]]
        (with-meta
          lines
          (into
            (meta block)
            {:root (if (empty? root)
                      (gensym "root__")
                      (first root))}))))))

;; # Step 5. Group the innermost sequence of lines into blank-delimited chunks.

;; This next parsing step is mercifully simple. As before, we split
;; on the delimiter, here blank lines.

(def split-on-blank-lines
  "Split the innermost sequence of lines on blanks."
  (mapcat
    (fn [block]
      (eduction (handle-blanks block)))))


;; # Step 6. Turn the remaining strings into "entry" maps.

;; The final step in parsing is to turn the lines, which are now divided up
;; in a maximally informative way, into maps representing their contents.

(def turn-lines-into-maps
  "Turn remaining strings into lexical entry maps."
  (mapcat
    (fn [lines]
      (map (divide-data-chunk-with-meta (meta lines)) lines))))

(def remove-blank-lexemes
  "Filters out the blanks."
  (filter :lexeme))
